{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2150bde-3551-42ec-90ff-1b621b0b7f92",
   "metadata": {},
   "source": [
    "# Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9147022-fca8-40ce-a17c-761c648e4ae9",
   "metadata": {},
   "source": [
    "Probability Mass Function (PMF) and Probability Density Function (PDF) are two fundamental concepts in probability theory and statistics used to describe the probability distribution of a random variable.\n",
    "\n",
    "# Probability Mass Function (PMF):\n",
    "The PMF is a function that maps each possible value of a discrete random variable to its probability of occurrence. It represents the probability that a random variable takes a certain value. The sum of probabilities of all possible values of the random variable is equal to 1. The PMF is defined as:\n",
    "\n",
    "PMF(x) = P(X = x)\n",
    "\n",
    "where X is a random variable, x is a possible value that X can take, and P(X = x) is the probability that X takes the value x.\n",
    "\n",
    "Example: Consider the roll of a fair six-sided die. The possible values that the die can take are 1, 2, 3, 4, 5, and 6, each with a probability of 1/6. The PMF of the random variable X, which represents the number on the top face of the die, is:\n",
    "\n",
    "PMF(1) = 1/6\n",
    "\n",
    "PMF(2) = 1/6\n",
    "\n",
    "PMF(3) = 1/6\n",
    "\n",
    "PMF(4) = 1/6\n",
    "\n",
    "PMF(5) = 1/6\n",
    "\n",
    "PMF(6) = 1/6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600019bd-c26c-4966-b0e6-ae0529646581",
   "metadata": {},
   "source": [
    "# Probability Density Function (PDF):\n",
    "PDF is a function that describes the probability density of a continuous random variable. It represents the probability that a random variable falls within a certain range of values. The area under the curve of the PDF between any two points represents the probability that the random variable falls within that range. The integral of the PDF over the entire domain is equal to 1. The PDF is defined as:\n",
    "\n",
    "PDF(x) = dF(x)/dx\n",
    "\n",
    "Example: Consider a normal distribution with a mean of 0 and a standard deviation of 1. The PDF of the random variable X, which represents the values that X can take, is:\n",
    "\n",
    "PDF(x) = 1/(sqrt(2pi)) exp(-(x^2)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe547a8-3c18-4781-9ca8-1521129ecb6f",
   "metadata": {},
   "source": [
    "# Q2. What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de986661-5b7b-41c0-8e9f-39ce9e7e439a",
   "metadata": {},
   "source": [
    "The Cumulative Distribution Function (CDF) is a fundamental concept in probability theory and statistics that describes the probability that a random variable takes a value less than or equal to a given value. It is defined for both discrete and continuous random variables.\n",
    "\n",
    "For a discrete random variable X, the CDF is defined as:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "where x is any real number, and P(X ≤ x) is the probability that X takes a value less than or equal to x.\n",
    "\n",
    "For a continuous random variable X, the CDF is defined as the integral of the PDF from negative infinity to x:\n",
    "\n",
    "F(x) = ∫{-∞, x} PDF(t) dt\n",
    "\n",
    "where PDF(x) is the Probability Density Function of X.\n",
    "\n",
    "Example: Consider the roll of a fair six-sided die. The possible values that the die can take are 1, 2, 3, 4, 5, and 6, each with a probability of 1/6. The CDF of the random variable X, which represents the number on the top face of the die, is:\n",
    "\n",
    "F(x) = P(X ≤ x)\n",
    "\n",
    "= 0 for x < 1\n",
    "\n",
    "= 1/6 for 1 ≤ x < 2\n",
    "\n",
    "= 2/6 for 2 ≤ x < 3\n",
    "\n",
    "= 3/6 for 3 ≤ x < 4\n",
    "\n",
    "= 4/6 for 4 ≤ x < 5\n",
    "\n",
    "= 5/6 for 5 ≤ x < 6\n",
    "\n",
    "= 1 for x ≥ 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd8fc1c-8423-4820-b1d8-0252dbe95976",
   "metadata": {},
   "source": [
    "# Q3. What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution.\n",
    "Some examples of situations where the normal distribution might be used as a model include:\n",
    "\n",
    "Heights or weights of a population: The normal distribution can be used to model the distribution of heights or weights of a population.\n",
    "\n",
    "# 1.Test scores:\n",
    "The normal distribution can be used to model the distribution of test scores in a population.\n",
    "\n",
    "# 2.Measurement errors:\n",
    "The normal distribution can be used to model the distribution of errors in measurements, such as errors in laboratory measurements.\n",
    "\n",
    "# 3.Financial returns:\n",
    "The normal distribution can be used to model the distribution of financial returns, such as stock prices.\n",
    "\n",
    "# 4.Time taken to complete a task:\n",
    "The normal distribution can be used to model the distribution of time taken to complete a task, such as the time taken to fill an order in a factory.\n",
    "\n",
    "The normal distribution is a symmetric distribution, which means that the mean, median, and mode are all equal. The shape of the distribution is bell-shaped, and the total area under the curve is equal to 1. The standard normal distribution is a special case of the normal distribution with a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "The normal distribution is often used as a model in statistical analysis because of its properties, such as the central limit theorem, which states that the sum of a large number of independent and identically distributed random variables will tend to a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01546b64-84fb-4f85-97e7-645b513318af",
   "metadata": {},
   "source": [
    "# Q4. Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c2d406-3161-49dd-aa9c-3c1189a8845f",
   "metadata": {},
   "source": [
    "# Importance of Normal Distribution\n",
    "The normal distribution is an important probability distribution in math and statistics because many continuous data in nature and psychology display this bell-shaped curve when compiled and graphed.\n",
    "\n",
    "The normal distribution is also termed as a gaussian distribution. It represents the data from the mean position. In the graph form normal distribution appears as a bell curve.\n",
    "\n",
    "The normal distribution is widely used in financing industries. To examine the price action of the stocks and to account for the returns in the assent class.\n",
    "\n",
    "The normal distribution is symmetric and has a skewness of zero. The skewness measures the symmetry of a distribution with respect to the normal distribution.\n",
    "\n",
    "# Few Real-Life examples of Normal Distribution.\n",
    "\n",
    "# Height\n",
    "The height of people is an example of normal distribution. Most of the people in a specific population are of average height. The number of people taller and shorter than the average height people is almost equal, and a very small number of people are either extremely tall or extremely short\n",
    "\n",
    "# IQ\n",
    "\n",
    "In this scenario of increasing competition, most parents, as well as children, want to analyze the Intelligent Quotient level. Well, the IQ of a particular population is a normal distribution curve; where the IQ of a majority of the people in the population lies in the normal range whereas the IQ of the rest of the population lives in the deviated range.\n",
    "\n",
    "# Technical Stock Market\n",
    "\n",
    "Most of us have heard about the rise and fall in the prices of shares in the stock market. These changes in the log values of Forex rates, price indices, and stock prices return often form a bell-shaped curve. For stock returns, the standard deviation is often called volatility. If returns are normally distributed, more than 99 percent of the returns are expected to fall within the deviations of the mean value. Such characteristics of the bell-shaped normal distribution allow analysts and investors to make statistical inferences about the expected return and risk of stocks.\n",
    "\n",
    "# Birth Weight\n",
    "\n",
    "The normal birth weight of a newborn ranges from 2.5 to 3.5 kg. The majority of newborns have normal birthweight whereas only a few percent of newborns have a weight higher or lower than normal. Hence, birth weight also follows the normal distribution curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b460f689-7a81-4ddf-b566-7a99baa47a47",
   "metadata": {},
   "source": [
    "# Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883fdbe8-8385-47a9-8885-64b73f7e3416",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that models the outcome of a single binary event. It takes a single parameter p, which represents the probability of success for the event, and outputs a probability distribution for the event's outcomes.\n",
    "\n",
    "Example: Consider flipping a fair coin. The Bernoulli distribution models this as a binary event where the outcome is either heads or tails. If we define \"success\" as getting heads, then the probability of success is 0.5, and the probability of failure (getting tails) is also 0.5. The Bernoulli distribution would output a probability distribution where the probability of success is 0.5 and the probability of failure is 0.5.\n",
    "\n",
    "The key difference between the Bernoulli distribution and the binomial distribution is that the Bernoulli distribution models the outcome of a single event, while the binomial distribution models the number of successes in a fixed number of independent and identical Bernoulli trials. In other words, the binomial distribution is the sum of multiple independent Bernoulli random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41ff4e7-e224-462a-8b39-1c62a6a1af87",
   "metadata": {},
   "source": [
    "# Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ff0f7e-6ee2-403a-9318-0f7217ea8ea0",
   "metadata": {},
   "source": [
    "We can use the z-table to solve this question.\n",
    "\n",
    "The appropriate formula to use is: z = (x - μ) / σ\n",
    "\n",
    "where x is the value of the observation you are interested in (in this case, x = 60), μ is the mean of the dataset, and σ is the standard deviation of the dataset.\n",
    "\n",
    "Substituting the values given in the question, we get: z = (60 - 50) / 10 = 1\n",
    "\n",
    "Now, we need to use the z-table to find the probability that a z-score is greater than 1.\n",
    "\n",
    "Using the z-table, we look up the probability corresponding to a z-score of 1.00 in the positive z-score column. The table tells us that the probability is 0.8413.\n",
    "\n",
    "The probabilty that we got from z-table is the probability of randomly selected number less than 60, because z-table gives us the probability of the values on the left side of 60. But we need the values on the right side (greater than 60) of 60. So we can get that probability by subtracting 0.8413 from 1 as: 1 - 0.8413 = 0.1587"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1113195-7419-443d-973a-9dc37c67ea4f",
   "metadata": {},
   "source": [
    "# Q7. Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d337cc2f-971e-4047-b20b-870ab32f1f3f",
   "metadata": {},
   "source": [
    "Uniform distribution, also known as a rectangular distribution, is a probability distribution where all possible outcomes are equally likely to occur. It is often used in statistics to model situations where each outcome is equally likely to occur, such as rolling a fair die or picking a card from a well-shuffled deck.\n",
    "\n",
    "Example: Rolling a fair six-sided die: When rolling the die, each face has an equal probability of showing up, which is 1/6 or approximately 0.1667. This means that any number between 1 and 6 is equally likely to be rolled, and the probability of rolling any particular number is 1/6.\n",
    "\n",
    "In the above examples, the probability density function of the uniform distribution is constant over the entire range of possible outcomes. That is, the probability of any particular outcome is proportional to the size of the range of possible outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e487392f-514c-4fda-8bd0-7c0b38b354a0",
   "metadata": {},
   "source": [
    "# Q8. What is the z score? State the importance of the z score.\n",
    "The z-score is a statistical measure that expresses how far a data point is from the mean of a distribution in terms of standard deviations. The formula for calculating the z-score of a data point is: z = (x - μ) / σ\n",
    "\n",
    "Where x is the data point, μ is the mean of the distribution, and σ is the standard deviation.\n",
    "\n",
    "# Importance:\n",
    "1-The z-score is important because it allows us to standardize data from different distributions, which can then be compared and analyzed more easily. By converting data into z-scores, we can compare observations from different samples or populations and make meaningful statements about their relative positions.\n",
    "\n",
    "2-The z-score is also useful in hypothesis testing, where it is used to calculate the probability of observing a value as extreme as the one observed, assuming a certain null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2180a27-90d2-467e-b78e-aded3c6d29d7",
   "metadata": {},
   "source": [
    "# Q9. What is Central Limit Theorem? State the significance of the Central Limit Theorem.\n",
    "The Central Limit Theorem (CLT) is a fundamental result in probability theory and statistics that describes the behavior of the sum or average of a large number of independent and identically distributed random variables. It states that, under certain conditions, the sum or average of such variables will converge to a normal distribution, regardless of the distribution of the individual variables.\n",
    "\n",
    "The significance of the CLT is that it provides a theoretical foundation for many statistical techniques that assume normally distributed data. For example, many hypothesis tests and confidence intervals rely on the assumption of normality, which is often justified by the CLT.\n",
    "\n",
    "Additionally, the CLT is important in practical applications such as quality control, where it is often necessary to estimate the mean and variance of a population based on a sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa124a9b-a0bf-41ac-9702-52ea84868f96",
   "metadata": {},
   "source": [
    "# Q10. State the assumptions of the Central Limit Theorem.\n",
    "The assumptions of the Central Limit Theorem are:\n",
    "\n",
    "1-Independence: The observations in the sample are independent of each other, meaning that the outcome of one observation does not influence the outcome of another observation.\n",
    "\n",
    "2-Sample size: The sample size is sufficiently large. The larger the sample size, the better the approximation to the normal distribution.\n",
    "\n",
    "3-Identically distributed: The sample data comes from a population that has a well-defined mean and variance. The observations in the sample are identically distributed, meaning that they come from the same population.\n",
    "\n",
    "4-Finite variance: The population has a finite variance. This assumption ensures that the sample variance is also finite.\n",
    "\n",
    "5-Non-skewed population distribution: The population distribution is not strongly skewed. A strongly skewed population distribution can affect the validity of the Central Limit Theorem, and a larger sample size may be required to approximate a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c0b248-2016-4092-bff5-782479f5a1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
